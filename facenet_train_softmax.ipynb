{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** *****\n",
      "\n",
      "C:\\Users\\DS\\Yonsei_Capstone\n",
      "\n",
      "***** *****\n",
      "\n",
      "Running on device: cuda:0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "from facenet_config import InceptionResnetV1, fixed_image_standardization\n",
    "from facenet_capstone.utils import training\n",
    "# from utils.logits import CosFace\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# Check current directory\n",
    "cwd = os.getcwd()\n",
    "print('\\n***** *****\\n')\n",
    "print(cwd)\n",
    "\n",
    "# Determine if an nvidia GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# For reproducibility, Seed the RNG for all devices (both CPU and CUDA):\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "# np.random.seed(0)\n",
    "# random.seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print('\\n***** *****\\n')\n",
    "print('Running on device: {}'.format(device)) \n",
    "\n",
    "# ***** *****\n",
    "\n",
    "# Set training parameters\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "workers = 0 if os.name == 'nt' else 8 #nt for Windows\n",
    "print(workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate training and testing folders\n",
    "train_dir = 'D:/TinyFace_Closed/train'\n",
    "test_dir = 'D:/TinyFace_Closed/test'\n",
    "\n",
    "train_trans = transforms.Compose( [ transforms.Resize((160,160)),\n",
    "                                    transforms.RandomHorizontalFlip(p=0.6), \n",
    "                                    np.float32, transforms.ToTensor(), fixed_image_standardization ] )\n",
    "\n",
    "test_trans = transforms.Compose( [ transforms.Resize((160,160)),\n",
    "                                    # transforms.RandomHorizontalFlip(p=0.6), \n",
    "                                    np.float32, transforms.ToTensor(), fixed_image_standardization ] )\n",
    "\n",
    "train_set = datasets.ImageFolder(train_dir, transform = train_trans)\n",
    "test_set = datasets.ImageFolder(test_dir, transform = test_trans)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = workers)\n",
    "\n",
    "assert(train_set.class_to_idx.items() == test_set.class_to_idx.items()) #assertionError if !=\n",
    "\n",
    "class_names = train_set.classes\n",
    "\n",
    "# print(train_set.class_to_idx)\n",
    "# print(train_set.class_to_idx.keys())\n",
    "# print(train_set.class_to_idx.values())\n",
    "# print(train_set.class_to_idx.items())\n",
    "# print(test_set.class_to_idx.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** *****\n",
      "\n",
      "Loading Pre-Learned InceptionResnetV1 ( Pre-Trained w.r.t. VGGFace2 ) ... \n",
      "\n",
      "\n",
      "Learnable Paramater List\n",
      "------------------------\n",
      "\n",
      "resnet\t: logits.weight\n",
      "resnet\t: logits.bias\n"
     ]
    }
   ],
   "source": [
    "# Load pre-learned InceptionResnetV1 \n",
    "print('\\n***** *****\\n')\n",
    "print('Loading Pre-Learned InceptionResnetV1 ( Pre-Trained w.r.t. VGGFace2 ) ... ' )  \n",
    "print()\n",
    "\n",
    "resnet = InceptionResnetV1(pretrained = 'vggface2', classify=True, num_classes=len(class_names))\n",
    "\n",
    "# print state_dict of the model \n",
    "'''\n",
    "print(\"resnet's state_dict:\")\n",
    "for param_tensor in resnet.state_dict():\n",
    "    print(param_tensor, \"\\t\", resnet.state_dict()[param_tensor].size())\n",
    "'''\n",
    "# resnet.logits = CosFace(in_features = resnet.last_linear.out_features, out_features = len(class_names))\n",
    "resnet.to(device)\n",
    "\n",
    "# print(resnet)\n",
    "# print(len(class_names))\n",
    "\n",
    "# ***** *****\n",
    "\n",
    "# Resnet : Determine parameters to be freezed, or unfreezed\n",
    "# Retrain only logit >>> softmax classifier\n",
    "for name, param in resnet.named_parameters():\n",
    "    # if name in ['last_linear.weight', 'last_linear.bias', 'last_bn.weight', 'last_bn.bias']:\n",
    "    if name in ['logits.weight', 'logits.bias']:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False #False if only the last fc layer\n",
    "        \n",
    "# Resnet : Display all learnable parameters\n",
    "print()\n",
    "print('Learnable Paramater List')\n",
    "print('-' *24)\n",
    "print()\n",
    "\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print('resnet\\t:', name)\n",
    "\n",
    "# ***** *****\n",
    "\n",
    "# Freeze all batch normalization (BN) parameters\n",
    "for name, layer in resnet.named_modules():\n",
    "    if isinstance(layer,torch.nn.BatchNorm2d):  \n",
    "        layer.weight.requires_grad = False\n",
    "        layer.bias.requires_grad = False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lr, lr_scheduler, weight_decay\n",
    "lr = 0.001\n",
    "milestones = [12, 24, 36, 48]\n",
    "weight_decay = 0.0000\n",
    "\n",
    "# ***** *****\n",
    "# Set an optimizer, scheduler, etc.\n",
    "net_params = resnet.parameters()\n",
    "optimizer = optim.Adam(net_params, lr = lr, weight_decay = weight_decay)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = milestones, gamma = 0.1)\n",
    "\n",
    "# ***** *****\n",
    "\n",
    "# Define loss and evaluation functions\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "--------\n",
      "Test |    30/30   | loss:    8.7018 | fps:  559.3226 | acc:    0.0013   \n",
      "\n",
      "Epoch 1/40\n",
      "----------\n",
      "Train |    96/96   | loss:    7.7878 | fps:  576.1533 | acc:    0.0587   \n",
      "Test |    30/30   | loss:    6.8420 | fps:  710.9582 | acc:    0.0807   \n",
      "\n",
      "Epoch 2/40\n",
      "----------\n",
      "Train |    96/96   | loss:    5.1272 | fps:  699.7684 | acc:    0.2488   \n",
      "Test |    30/30   | loss:    5.7310 | fps:  706.7406 | acc:    0.1802   \n",
      "\n",
      "Epoch 3/40\n",
      "----------\n",
      "Train |    96/96   | loss:    3.4506 | fps:  697.0641 | acc:    0.4933   \n",
      "Test |    30/30   | loss:    5.0510 | fps:  709.7490 | acc:    0.2628   \n",
      "\n",
      "Epoch 4/40\n",
      "----------\n",
      "Train |    96/96   | loss:    2.3915 | fps:  692.6949 | acc:    0.6776   \n",
      "Test |    30/30   | loss:    4.6289 | fps:  715.3400 | acc:    0.3044   \n",
      "\n",
      "Epoch 5/40\n",
      "----------\n",
      "Train |    96/96   | loss:    1.7347 | fps:  694.5745 | acc:    0.7774   \n",
      "Test |    30/30   | loss:    4.4151 | fps:  723.3185 | acc:    0.3240   \n",
      "\n",
      "Epoch 6/40\n",
      "----------\n",
      "Train |    96/96   | loss:    1.3670 | fps:  697.7305 | acc:    0.8184   \n",
      "Test |    30/30   | loss:    4.3554 | fps:  708.8527 | acc:    0.3297   \n",
      "\n",
      "Epoch 7/40\n",
      "----------\n",
      "Train |    96/96   | loss:    1.1523 | fps:  693.7303 | acc:    0.8412   \n",
      "Test |    30/30   | loss:    4.3384 | fps:  709.5764 | acc:    0.3268   \n",
      "\n",
      "Epoch 8/40\n",
      "----------\n",
      "Train |    96/96   | loss:    1.0113 | fps:  701.8553 | acc:    0.8562   \n",
      "Test |    30/30   | loss:    4.3715 | fps:  707.3977 | acc:    0.3164   \n",
      "\n",
      "Epoch 9/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.9100 | fps:  696.1584 | acc:    0.8647   \n",
      "Test |    30/30   | loss:    4.3868 | fps:  719.4311 | acc:    0.3125   \n",
      "\n",
      "Epoch 10/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.8255 | fps:  702.2046 | acc:    0.8738   \n",
      "Test |    30/30   | loss:    4.4470 | fps:  709.5351 | acc:    0.3120   \n",
      "\n",
      "Epoch 11/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.7657 | fps:  693.4611 | acc:    0.8818   \n",
      "Test |    30/30   | loss:    4.4590 | fps:  712.2285 | acc:    0.3159   \n",
      "\n",
      "Epoch 12/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.7220 | fps:  696.6616 | acc:    0.8837   \n",
      "Test |    30/30   | loss:    4.5061 | fps:  708.8090 | acc:    0.3099   \n",
      "\n",
      "Epoch 13/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.6160 | fps:  686.5567 | acc:    0.9066   \n",
      "Test |    30/30   | loss:    4.5089 | fps:  693.1801 | acc:    0.3125   \n",
      "\n",
      "Epoch 14/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.6122 | fps:  687.8314 | acc:    0.9083   \n",
      "Test |    30/30   | loss:    4.5125 | fps:  708.9978 | acc:    0.3109   \n",
      "\n",
      "Epoch 15/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.6010 | fps:  692.5296 | acc:    0.9083   \n",
      "Test |    30/30   | loss:    4.5123 | fps:  707.1208 | acc:    0.3117   \n",
      "\n",
      "Epoch 16/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5993 | fps:  685.0847 | acc:    0.9105   \n",
      "Test |    30/30   | loss:    4.5125 | fps:  707.0590 | acc:    0.3112   \n",
      "\n",
      "Epoch 17/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5948 | fps:  686.0220 | acc:    0.9087   \n",
      "Test |    30/30   | loss:    4.5203 | fps:  717.7259 | acc:    0.3109   \n",
      "\n",
      "Epoch 18/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5814 | fps:  600.5461 | acc:    0.9129   \n",
      "Test |    30/30   | loss:    4.5219 | fps:  603.2257 | acc:    0.3102   \n",
      "\n",
      "Epoch 19/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5843 | fps:  603.2066 | acc:    0.9107   \n",
      "Test |    30/30   | loss:    4.5186 | fps:  609.4199 | acc:    0.3128   \n",
      "\n",
      "Epoch 20/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5776 | fps:  602.3876 | acc:    0.9125   \n",
      "Test |    30/30   | loss:    4.5176 | fps:  512.1832 | acc:    0.3125   \n",
      "\n",
      "Epoch 21/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5817 | fps:  454.8386 | acc:    0.9110   \n",
      "Test |    30/30   | loss:    4.5200 | fps:  461.5576 | acc:    0.3130   \n",
      "\n",
      "Epoch 22/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5693 | fps:  453.3940 | acc:    0.9137   \n",
      "Test |    30/30   | loss:    4.5277 | fps:  456.7979 | acc:    0.3125   \n",
      "\n",
      "Epoch 23/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5709 | fps:  455.4765 | acc:    0.9125   \n",
      "Test |    30/30   | loss:    4.5294 | fps:  459.0150 | acc:    0.3135   \n",
      "\n",
      "Epoch 24/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5679 | fps:  455.5680 | acc:    0.9126   \n",
      "Test |    30/30   | loss:    4.5404 | fps:  458.3388 | acc:    0.3138   \n",
      "\n",
      "Epoch 25/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5549 | fps:  455.0564 | acc:    0.9151   \n",
      "Test |    30/30   | loss:    4.5373 | fps:  462.6123 | acc:    0.3122   \n",
      "\n",
      "Epoch 26/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5554 | fps:  455.5697 | acc:    0.9139   \n",
      "Test |    30/30   | loss:    4.5378 | fps:  454.7351 | acc:    0.3112   \n",
      "\n",
      "Epoch 27/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5613 | fps:  446.5771 | acc:    0.9126   \n",
      "Test |    30/30   | loss:    4.5370 | fps:  461.1430 | acc:    0.3135   \n",
      "\n",
      "Epoch 28/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5514 | fps:  454.8156 | acc:    0.9147   \n",
      "Test |    30/30   | loss:    4.5444 | fps:  451.8072 | acc:    0.3104   \n",
      "\n",
      "Epoch 29/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5511 | fps:  455.0890 | acc:    0.9140   \n",
      "Test |    30/30   | loss:    4.5504 | fps:  445.5539 | acc:    0.3099   \n",
      "\n",
      "Epoch 30/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5548 | fps:  443.5201 | acc:    0.9134   \n",
      "Test |    30/30   | loss:    4.5397 | fps:  453.4047 | acc:    0.3122   \n",
      "\n",
      "Epoch 31/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5545 | fps:  447.5335 | acc:    0.9145   \n",
      "Test |    30/30   | loss:    4.5402 | fps:  447.2337 | acc:    0.3115   \n",
      "\n",
      "Epoch 32/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5477 | fps:  449.2595 | acc:    0.9147   \n",
      "Test |    30/30   | loss:    4.5403 | fps:  462.9410 | acc:    0.3089   \n",
      "\n",
      "Epoch 33/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5530 | fps:  453.8784 | acc:    0.9158   \n",
      "Test |    30/30   | loss:    4.5460 | fps:  446.4624 | acc:    0.3135   \n",
      "\n",
      "Epoch 34/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5510 | fps:  441.4891 | acc:    0.9140   \n",
      "Test |    30/30   | loss:    4.5346 | fps:  446.4155 | acc:    0.3122   \n",
      "\n",
      "Epoch 35/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5463 | fps:  445.4417 | acc:    0.9160   \n",
      "Test |    30/30   | loss:    4.5419 | fps:  444.0312 | acc:    0.3122   \n",
      "\n",
      "Epoch 36/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5533 | fps:  440.9434 | acc:    0.9157   \n",
      "Test |    30/30   | loss:    4.5314 | fps:  442.9143 | acc:    0.3109   \n",
      "\n",
      "Epoch 37/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5521 | fps:  440.9486 | acc:    0.9154   \n",
      "Test |    30/30   | loss:    4.5411 | fps:  440.2057 | acc:    0.3104   \n",
      "\n",
      "Epoch 38/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5540 | fps:  443.6582 | acc:    0.9138   \n",
      "Test |    30/30   | loss:    4.5414 | fps:  464.7215 | acc:    0.3148   \n",
      "\n",
      "Epoch 39/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5513 | fps:  455.9485 | acc:    0.9157   \n",
      "Test |    30/30   | loss:    4.5414 | fps:  461.5422 | acc:    0.3096   \n",
      "\n",
      "Epoch 40/40\n",
      "----------\n",
      "Train |    96/96   | loss:    0.5518 | fps:  457.9611 | acc:    0.9161   \n",
      "Test |    30/30   | loss:    4.5336 | fps:  460.9912 | acc:    0.3117   \n"
     ]
    }
   ],
   "source": [
    "# Start fine-tuning resnset\n",
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "# ***** ***** print initial evaluation output\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 8)\n",
    "\n",
    "resnet.eval()\n",
    "\n",
    "training.run_training(resnet, loss_fn, test_loader,\n",
    "                     batch_metrics=metrics, show_running=True, device=device,\n",
    "                     writer=writer)\n",
    "\n",
    "# ***** ***** training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    \n",
    "    for layer in resnet.modules():\n",
    "        if isinstance(layer,torch.nn.modules.batchnorm.BatchNorm2d):\n",
    "            #print(layer)\n",
    "            layer.eval()\n",
    "    \n",
    "    training.run_training(resnet, loss_fn, train_loader, optimizer, scheduler, #training\n",
    "                          batch_metrics=metrics, show_running=True, device=device,\n",
    "                          writer=writer)\n",
    "    \n",
    "    # ***** evaluation mode\n",
    "\n",
    "    resnet.eval()\n",
    "\n",
    "    training.run_training(resnet, loss_fn, test_loader,\n",
    "                         batch_metrics=metrics, show_running=True, device=device,\n",
    "                         writer=writer)\n",
    "\n",
    "# ***** *****\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weight = 'C:/Users/DS/Yonsei_Capstone/save_model/resnet_1.pt'\n",
    "path_all = 'C:/Users/DS/Yonsei_Capstone/save_model/resnet.tar'\n",
    "torch.save(resnet.state_dict(),path_weight)\n",
    "torch.save(resnet,path_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
